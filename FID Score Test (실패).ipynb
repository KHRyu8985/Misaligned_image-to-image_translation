{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1159967",
   "metadata": {},
   "source": [
    "# 첫번째 시도 - 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c619e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import inception_v3\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "# 평균과 공분산 계산 함수\n",
    "def calculate_activation_statistics(x, model, device):\n",
    "    # Inception 모델의 중간층(layer)까지 모델 정의\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    upsample = torch.nn.Upsample(size=(299, 299), mode='bilinear').to(device)\n",
    "    block_idx = inception_v3.BLOCK_INDEX_BY_DIM[2048]\n",
    "    model = torch.nn.Sequential(\n",
    "        *list(model.children())[:block_idx+1]\n",
    "    )\n",
    "\n",
    "    # 데이터셋의 데이터를 Inception 모델에 입력하여 중간층의 출력값을 추출\n",
    "    n = x.shape[0]\n",
    "    x = upsample(x)\n",
    "    with torch.no_grad():\n",
    "        x = model(x.to(device))\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    # 평균과 공분산 계산\n",
    "    mean = torch.mean(x, dim=0)\n",
    "    cov = torch.matmul(x.T, x) / n - torch.matmul(mean.T, mean)\n",
    "    return mean.cpu().numpy(), cov.cpu().numpy()\n",
    "\n",
    "# FID 계산 함수\n",
    "def calculate_fid(real_images, fake_images, model, device):\n",
    "    # 실제 데이터셋에 대한 평균과 공분산 계산\n",
    "    m1, s1 = calculate_activation_statistics(real_images, model, device)\n",
    "\n",
    "    # 생성된 데이터셋에 대한 평균과 공분산 계산\n",
    "    m2, s2 = calculate_activation_statistics(fake_images, model, device)\n",
    "\n",
    "    # 평균 제곱근 차이와 공분산 합계의 제곱근 계산\n",
    "    diff = m1 - m2\n",
    "    covmean, _ = linalg.sqrtm(s1.dot(s2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        offset = np.eye(s1.shape[0]) * 1e-6\n",
    "        covmean = linalg.sqrtm((s1 + offset).dot(s2 + offset))\n",
    "    fid = np.dot(diff, diff) + np.trace(s1 + s2 - 2 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ebde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Inception V3 모델 불러오기\n",
    "model = inception_v3(pretrained=True, transform_input=False, aux_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c30ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_images와 fake_images를 텐서 형태로 준비\n",
    "# 이 텐서들은 적절한 전처리를 거친 후에 생성되어야 함\n",
    "real_images = torch.randn(32, 3, 299, 299)  # 예시를 위해 무작위 텐서 사용\n",
    "fake_images = torch.randn(32, 3, 299, 299)  # 예시를 위해 무작위 텐서 사용\n",
    "\n",
    "# FID 값을 계산\n",
    "fid = calculate_fid(real_images, fake_images, model, device)\n",
    "print(\"FID score:\", fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f03ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1af81c7b",
   "metadata": {},
   "source": [
    "# 두번째 시도 - 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import inception_v3\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "# 평균과 공분산 계산 함수\n",
    "def calculate_activation_statistics(x, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    upsample = torch.nn.Upsample(size=(299, 299), mode='bilinear').to(device)\n",
    "\n",
    "    # 데이터셋의 데이터를 Inception 모델에 입력하여 중간층의 출력값을 추출\n",
    "    n = x.shape[0]\n",
    "    x = upsample(x)\n",
    "    with torch.no_grad():\n",
    "        x = model(x.to(device))  # 주목: 중간층의 출력값만 사용\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    # 평균과 공분산 계산\n",
    "    mean = torch.mean(x, dim=0)\n",
    "    cov = torch.matmul(x.T, x) / n - torch.matmul(mean.T, mean)\n",
    "    return mean.cpu().numpy(), cov.cpu().numpy()\n",
    "\n",
    "\n",
    "# FID 계산 함수\n",
    "def calculate_fid(real_images, fake_images, model, device):\n",
    "    # 실제 데이터셋에 대한 평균과 공분산 계산\n",
    "    m1, s1 = calculate_activation_statistics(real_images, model, device)\n",
    "\n",
    "    # 생성된 데이터셋에 대한 평균과 공분산 계산\n",
    "    m2, s2 = calculate_activation_statistics(fake_images, model, device)\n",
    "\n",
    "    # 평균 제곱근 차이와 공분산 합계의 제곱근 계산\n",
    "    diff = m1 - m2\n",
    "    covmean, _ = linalg.sqrtm(s1.dot(s2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        offset = np.eye(s1.shape[0]) * 1e-6\n",
    "        covmean = linalg.sqrtm((s1 + offset).dot(s2 + offset))\n",
    "    fid = np.dot(diff, diff) + np.trace(s1 + s2 - 2 * covmean)\n",
    "    return fid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ec73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Inception V3 모델 불러오기\n",
    "model = inception_v3(pretrained=True, transform_input=False, aux_logits=True)\n",
    "\n",
    "# Inception 모델의 중간층(layer)까지 모델 정의\n",
    "# 여기에서, inception_v3에서 미리 정의된 중간층 인덱스를 사용할 수 없으므로,\n",
    "# 미리 정의된 인덱스 값인 9를 직접 사용합니다.\n",
    "model = torch.nn.Sequential(\n",
    "    *list(model.children())[:9+1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f360228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_images와 fake_images를 텐서 형태로 준비\n",
    "# 이 텐서들은 적절한 전처리를 거친 후에 생성되어야 함\n",
    "real_images = torch.randn(32, 3, 299, 299)  # 예시를 위해 무작위 텐서 사용\n",
    "fake_images = torch.randn(32, 3, 299, 299)  # 예시를 위해 무작위 텐서 사용\n",
    "\n",
    "# FID 값을 계산\n",
    "fid = calculate_fid(real_images, fake_images, model, device)\n",
    "print(\"FID score:\", fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 입력 이미지의 크기가 256x256인 경우\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/IXI0_fake_B.png\"\n",
    "# 이미지 불러오기\n",
    "image = Image.open(path).convert('RGB')\n",
    "# 이미지를 tensor로 변환하기\n",
    "fake_images = torch.tensor(np.array(image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "# 출력\n",
    "print(fake_images.shape)\n",
    "\n",
    "path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/IXI0_real_B.png\"\n",
    "# 이미지 불러오기\n",
    "image = Image.open(path).convert('RGB')\n",
    "# 이미지를 tensor로 변환하기\n",
    "real_images = torch.tensor(np.array(image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "# 출력\n",
    "print(real_images.shape)\n",
    "\n",
    "# FID 값을 계산\n",
    "fid = calculate_fid(real_images, fake_images, model, device)\n",
    "print(\"FID score:\", fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 입력 이미지의 크기가 256x256인 경우\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "image = Image.open(path).convert('RGB')\n",
    "fake_images = transform(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc2720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 입력 이미지의 크기가 256x256인 경우\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/IXI0_real_B.png\"\n",
    "\n",
    "image = Image.open(path).convert('RGB')\n",
    "fake_images = transform(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d983ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fake_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18c9cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae34298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff881cc9",
   "metadata": {},
   "source": [
    "# 세번째 시도 - 실패\n",
    "출처: https://github.com/mseitzer/pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870a24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-fid\n",
      "  Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from pytorch-fid) (1.9.1)\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from pytorch-fid) (0.14.1)\n",
      "Requirement already satisfied: numpy in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from pytorch-fid) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.0.1 in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from pytorch-fid) (1.13.1)\n",
      "Requirement already satisfied: pillow in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from pytorch-fid) (9.4.0)\n",
      "Requirement already satisfied: typing_extensions in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from torch>=1.0.1->pytorch-fid) (4.5.0)\n",
      "Requirement already satisfied: requests in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from torchvision>=0.2.2->pytorch-fid) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/milab/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (1.26.14)\n",
      "Installing collected packages: pytorch-fid\n",
      "Successfully installed pytorch-fid-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12c2b714",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in /SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/real.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m fake_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/fake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 이미지 데이터셋 생성\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m real_images_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal_images_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCenterCrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m fake_images_dataset \u001b[38;5;241m=\u001b[39m dset\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39mfake_images_path,\n\u001b[1;32m     23\u001b[0m                                        transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     24\u001b[0m                                            transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                                 std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n\u001b[1;32m     29\u001b[0m                                        ]))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 데이터로더 생성\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/torchvision/datasets/folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     40\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m class_to_idx \u001b[38;5;241m=\u001b[39m {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/real."
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from pytorch_fid import fid_score\n",
    "\n",
    "# 실제 이미지 폴더 경로\n",
    "real_images_path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/real\"\n",
    "\n",
    "# 생성된 이미지 폴더 경로\n",
    "fake_images_path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/fake\"\n",
    "\n",
    "# 이미지 데이터셋 생성\n",
    "real_images_dataset = dset.ImageFolder(root=real_images_path,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.Resize(256),\n",
    "                                           transforms.CenterCrop(256),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                                std=[0.5, 0.5, 0.5])\n",
    "                                       ]))\n",
    "fake_images_dataset = dset.ImageFolder(root=fake_images_path,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.Resize(256),\n",
    "                                           transforms.CenterCrop(256),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                                std=[0.5, 0.5, 0.5])\n",
    "                                       ]))\n",
    "\n",
    "# 데이터로더 생성\n",
    "real_images_dataloader = torch.utils.data.DataLoader(real_images_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=8)\n",
    "fake_images_dataloader = torch.utils.data.DataLoader(fake_images_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=8)\n",
    "\n",
    "# FID 계산\n",
    "fid_value = fid_score.calculate_fid_given_paths([real_images_dataloader, fake_images_dataloader], dims=2048, batch_size=32, device='cuda')\n",
    "print('FID score:', fid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3472cca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not DataLoader",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 42\u001b[0m\n\u001b[1;32m     36\u001b[0m fake_images_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(fake_images_dataset,\n\u001b[1;32m     37\u001b[0m                                                       batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     38\u001b[0m                                                       shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m                                                       num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# FID 계산\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m fid_value \u001b[38;5;241m=\u001b[39m \u001b[43mfid_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_fid_given_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreal_images_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_images_dataloader\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFID score:\u001b[39m\u001b[38;5;124m'\u001b[39m, fid_value)\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/pytorch_fid/fid_score.py:252\u001b[0m, in \u001b[0;36mcalculate_fid_given_paths\u001b[0;34m(paths, batch_size, device, dims, num_workers)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the FID of two paths\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid path: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m p)\n\u001b[1;32m    255\u001b[0m block_idx \u001b[38;5;241m=\u001b[39m InceptionV3\u001b[38;5;241m.\u001b[39mBLOCK_INDEX_BY_DIM[dims]\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not DataLoader"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import DatasetFolder\n",
    "\n",
    "# 실제 이미지 폴더 경로\n",
    "real_images_path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/real\"\n",
    "\n",
    "# 생성된 이미지 폴더 경로\n",
    "fake_images_path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/fake\"\n",
    "\n",
    "# 이미지 데이터셋 생성\n",
    "real_images_dataset = DatasetFolder(root=real_images_path,\n",
    "                                    loader=lambda x: Image.open(x),\n",
    "                                    extensions=\".png\",\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(256),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                             std=[0.5, 0.5, 0.5])\n",
    "                                    ]))\n",
    "fake_images_dataset = DatasetFolder(root=fake_images_path,\n",
    "                                    loader=lambda x: Image.open(x),\n",
    "                                    extensions=\".png\",\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(256),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                             std=[0.5, 0.5, 0.5])\n",
    "                                    ]))\n",
    "\n",
    "# 데이터로더 생성\n",
    "real_images_dataloader = torch.utils.data.DataLoader(real_images_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=8)\n",
    "fake_images_dataloader = torch.utils.data.DataLoader(fake_images_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=8)\n",
    "\n",
    "# FID 계산\n",
    "fid_value = fid_score.calculate_fid_given_paths([real_images_dataloader, fake_images_dataloader], dims=2048, batch_size=32, device='cuda')\n",
    "print('FID score:', fid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebff8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "batch_size should be a positive integer value, but got batch_size=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m paths \u001b[38;5;241m=\u001b[39m [real_images_path, fake_images_path]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# fid_value = fid_score.calculate_fid_given_paths(paths, dims=2048, batch_size=32, device='cuda')\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# fid_value = fid_score.calculate_fid_given_paths(paths, dims=2048, batch_size=None, device='cuda')\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m fid_value \u001b[38;5;241m=\u001b[39m \u001b[43mfid_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_fid_given_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFID score:\u001b[39m\u001b[38;5;124m'\u001b[39m, fid_value)\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/pytorch_fid/fid_score.py:259\u001b[0m, in \u001b[0;36mcalculate_fid_given_paths\u001b[0;34m(paths, batch_size, device, dims, num_workers)\u001b[0m\n\u001b[1;32m    255\u001b[0m block_idx \u001b[38;5;241m=\u001b[39m InceptionV3\u001b[38;5;241m.\u001b[39mBLOCK_INDEX_BY_DIM[dims]\n\u001b[1;32m    257\u001b[0m model \u001b[38;5;241m=\u001b[39m InceptionV3([block_idx])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 259\u001b[0m m1, s1 \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_statistics_of_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m m2, s2 \u001b[38;5;241m=\u001b[39m compute_statistics_of_path(paths[\u001b[38;5;241m1\u001b[39m], model, batch_size,\n\u001b[1;32m    262\u001b[0m                                     dims, device, num_workers)\n\u001b[1;32m    263\u001b[0m fid_value \u001b[38;5;241m=\u001b[39m calculate_frechet_distance(m1, s1, m2, s2)\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/pytorch_fid/fid_score.py:243\u001b[0m, in \u001b[0;36mcompute_statistics_of_path\u001b[0;34m(path, model, batch_size, dims, device, num_workers)\u001b[0m\n\u001b[1;32m    240\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path)\n\u001b[1;32m    241\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([file \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m IMAGE_EXTENSIONS\n\u001b[1;32m    242\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ext))])\n\u001b[0;32m--> 243\u001b[0m     m, s \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_activation_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m, s\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/pytorch_fid/fid_score.py:228\u001b[0m, in \u001b[0;36mcalculate_activation_statistics\u001b[0;34m(files, model, batch_size, dims, device, num_workers)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_activation_statistics\u001b[39m(files, model, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m,\n\u001b[1;32m    210\u001b[0m                                     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculation of the statistics used by the FID.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    Params:\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    -- files       : List of image files paths\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m               the inception model.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     act \u001b[38;5;241m=\u001b[39m \u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     mu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(act, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    230\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(act, rowvar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/pytorch_fid/fid_score.py:122\u001b[0m, in \u001b[0;36mget_activations\u001b[0;34m(files, model, batch_size, dims, device, num_workers)\u001b[0m\n\u001b[1;32m    119\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(files)\n\u001b[1;32m    121\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ImagePathDataset(files, transforms\u001b[38;5;241m=\u001b[39mTF\u001b[38;5;241m.\u001b[39mToTensor())\n\u001b[0;32m--> 122\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m pred_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mlen\u001b[39m(files), dims))\n\u001b[1;32m    130\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    346\u001b[0m             sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m batch_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# auto_collation without custom batch_sampler\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     batch_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mBatchSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_last \u001b[38;5;241m=\u001b[39m drop_last\n",
      "File \u001b[0;32m~/anaconda3/envs/danny_py3.8.8/lib/python3.8/site-packages/torch/utils/data/sampler.py:232\u001b[0m, in \u001b[0;36mBatchSampler.__init__\u001b[0;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampler: Union[Sampler[\u001b[38;5;28mint\u001b[39m], Iterable[\u001b[38;5;28mint\u001b[39m]], batch_size: \u001b[38;5;28mint\u001b[39m, drop_last: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Since collections.abc.Iterable does not check for `__getitem__`, which\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# is one way for an object to be an iterable, we don't do an `isinstance`\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# check here.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    231\u001b[0m             batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size should be a positive integer value, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got batch_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_size))\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(drop_last, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(drop_last))\n",
      "\u001b[0;31mValueError\u001b[0m: batch_size should be a positive integer value, but got batch_size=0"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from pytorch_fid import fid_score\n",
    "import os\n",
    "\n",
    "# 실제 이미지 폴더 경로\n",
    "real_images_path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/real\"\n",
    "\n",
    "# 생성된 이미지 폴더 경로\n",
    "fake_images_path = \"/SSD3_8TB/Daniel/06_pGAN/pGAN-cGAN/results/1_pGAN_run_align/test_latest/images/fake\"\n",
    "\n",
    "# 이미지 데이터셋 생성\n",
    "real_images_dataset = dset.ImageFolder(root=real_images_path,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.Resize(256),\n",
    "                                           transforms.CenterCrop(256),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                                std=[0.5, 0.5, 0.5])\n",
    "                                       ]))\n",
    "fake_images_dataset = dset.ImageFolder(root=fake_images_path,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.Resize(256),\n",
    "                                           transforms.CenterCrop(256),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                                std=[0.5, 0.5, 0.5])\n",
    "                                       ]))\n",
    "\n",
    "# 데이터로더 생성\n",
    "real_images_dataloader = torch.utils.data.DataLoader(real_images_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=8)\n",
    "fake_images_dataloader = torch.utils.data.DataLoader(fake_images_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=8)\n",
    "\n",
    "# FID 계산\n",
    "paths = [real_images_path, fake_images_path]\n",
    "# fid_value = fid_score.calculate_fid_given_paths(paths, dims=2048, batch_size=32, device='cuda')\n",
    "# fid_value = fid_score.calculate_fid_given_paths(paths, dims=2048, batch_size=None, device='cuda')\n",
    "fid_value = fid_score.calculate_fid_given_paths(paths, dims=2048, batch_size=32, device='cuda')\n",
    "\n",
    "\n",
    "\n",
    "print('FID score:', fid_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danny_py3.8.8",
   "language": "python",
   "name": "danny_py3.8.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
