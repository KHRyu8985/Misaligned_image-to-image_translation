{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch-Lightning으로 기존 데이터로더를 구현하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainOption 살펴보기 (Daniel Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.train_options import TrainOptions\n",
    "import sys\n",
    "\n",
    "# Mimic the command-line arguments\n",
    "sys.argv = ['train.py', '--model', 'ourGAN', '--dataroot', 'datasets/IXI', '--name', 'ourGAN_run', \n",
    "            '--which_direction', 'BtoA', '--lambda_A', '100', '--batchSize', '16', '--output_nc', '1', \n",
    "            '--input_nc', '3', '--gpu_ids', '0', '--niter', '50', '--niter_decay', '50', \n",
    "            '--save_epoch_freq', '25', '--lambda_vgg', '100', '--checkpoints_dir', 'checkpoints/', \n",
    "            '--training', '--dataset_misalign']\n",
    "\n",
    "opt = TrainOptions()\n",
    "opt.initialize()\n",
    "args = opt.parser.parse_args()\n",
    "\n",
    "print(args.model)\n",
    "print(args.dataroot)\n",
    "print(args.name)\n",
    "print(args.niter_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "from typing import Sequence\n",
    "from monai.data import ArrayDataset, DataLoader, PersistentDataset\n",
    "from monai.transforms import Compose, RandAffine, Rand2DElastic, Rand3DElastic\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import nibabel as nib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('datasets/IXI/train/data.mat','r')\n",
    "\n",
    "print(\"data_x shape: \", f['data_x'].shape)\n",
    "print(\"data_y shape: \", f['data_y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = f['data_x'][:,:,20,0]\n",
    "aligned_t2 = f['data_y'][:,:,20,0]\n",
    "\n",
    "blend_and_transpose = lambda x, y, alpha=0.3: np.transpose(blend_images(x[None], y[None], alpha,cmap='hot'), (1, 2, 0))\n",
    "\"\"\"\n",
    "This lambda function blends two images and transposes the resulting image.\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "x : ndarray\n",
    "    First image to blend. Should be a 2D ndarray.\n",
    "y : ndarray\n",
    "    Second image to blend. Should be a 2D ndarray.\n",
    "alpha : float, optional\n",
    "    The weight for blending the images. The higher the alpha, the more weight for the second image. Default is 0.3.\n",
    "\n",
    "Returns:\n",
    "--------\n",
    "ndarray\n",
    "    The blended and transposed image. Should be a 2D ndarray.\n",
    "\n",
    "Examples:\n",
    "---------\n",
    ">>> img1 = np.random.rand(10, 10)\n",
    ">>> img2 = np.random.rand(10, 10)\n",
    ">>> blended_img = blend_and_transpose(img1, img2)\n",
    "\"\"\"\n",
    "blended_align = blend_and_transpose(t1, aligned_t2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misalign (Rigid, Elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monai.utils.set_determinism(10) # Fixes the seed (for reproducibility)\n",
    "\n",
    "image = aligned_t2[None]\n",
    "\n",
    "# Define the MONAI RandAffine transform\n",
    "rand_affine_transform = RandAffine(\n",
    "    mode=\"bilinear\",\n",
    "    prob=1.0,\n",
    "    spatial_size=None,\n",
    "    rotate_range=(0.2, 0.2),  # Rotation range in radians\n",
    "    shear_range=(0.1, 0.1),   # Shear range\n",
    "    translate_range=(5, 5),  # Translation range in pixels\n",
    "    padding_mode=\"border\",\n",
    ")\n",
    "\n",
    "# Define the MONAI Rand2DElastic transform\n",
    "rand_2d_elastic_transform = Rand2DElastic(\n",
    "    mode=\"bilinear\",\n",
    "    prob=1.0,\n",
    "    spacing=(30, 30), # Distance between control points\n",
    "    magnitude_range=(0.1, 0.1), # Deformation magnitude\n",
    "    rotate_range=(0.1, 0.1),\n",
    "    shear_range=(0.1, 0.1),\n",
    "    translate_range=(5, 5),\n",
    "    padding_mode=\"border\",\n",
    ")\n",
    "\n",
    "# Apply the transform\n",
    "misaligned_t2_rigid = rand_affine_transform(image)[0]\n",
    "misaligned_t2_elastic = rand_2d_elastic_transform(image)[0]\n",
    "\n",
    "blended_misalign_rigid = blend_and_transpose(t1, misaligned_t2_rigid) # Blended image \n",
    "blended_misalign_elastic = blend_and_transpose(t1, misaligned_t2_elastic) # Blended image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, siz=4, cmap=None):\n",
    "    \"\"\"\n",
    "    This function plots a list of images with corresponding labels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : list of ndarray\n",
    "        List of images. Each image should be a 2D or 3D ndarray.\n",
    "    labels : list of str\n",
    "        List of labels. Each label corresponds to an image.\n",
    "    siz : int, optional\n",
    "        Size of each image when plotted. Default is 4.\n",
    "    cmap : str, optional\n",
    "        Colormap to use for displaying images. If 'gray', the image will be displayed in grayscale. \n",
    "        Default is None, in which case the default colormap is used.\n",
    "        \n",
    "    Raises:\n",
    "    -------\n",
    "    AssertionError\n",
    "        If the number of images does not match the number of labels.\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> img1 = np.random.rand(10, 10)\n",
    "    >>> img2 = np.random.rand(10, 10)\n",
    "    >>> plot_images([img1, img2], ['Image 1', 'Image 2'])\n",
    "    \n",
    "    >>> img1 = np.random.rand(10, 10)\n",
    "    >>> img2 = np.random.rand(10, 10)\n",
    "    >>> plot_images([img1, img2], ['Image 1', 'Image 2'], cmap='gray')\n",
    "    \"\"\"\n",
    "    assert len(images) == len(labels), \"Mismatch in number of images and labels\"\n",
    "    n = len(images)\n",
    "    \n",
    "    plt.figure(figsize=(siz*n, siz))  # Adjust figure size based on number of images\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        if cmap == 'gray':\n",
    "            plt.gray()\n",
    "        plt.title(labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([aligned_t2,misaligned_t2_rigid, misaligned_t2_elastic], [\"Aligned\", \"Misaligned (Rigid)\", \"Misaligned (Elastic)\"],3, cmap='gray')\n",
    "\n",
    "plot_images([blended_align,blended_misalign_rigid, blended_misalign_elastic], [\"Aligned\", \"Misaligned (Rigid)\", \"Misaligned (Elastic)\"],3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of misalignment\n",
    "\n",
    "1. Mutual Information\n",
    "2. Cross-Correlation\n",
    "3. Target Registration Error (TRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_mutual_info(image1, image2):\n",
    "    \"\"\"\n",
    "    This function calculates the mutual information between two images.\n",
    "\n",
    "    Parameters:\n",
    "    image1 (np.array): The first image\n",
    "    image2 (np.array): The second image\n",
    "\n",
    "    Returns:\n",
    "    float: The mutual information score\n",
    "    \"\"\"\n",
    "    hist_2d, _, _ = np.histogram2d(image1.ravel(), image2.ravel(), bins=20)\n",
    "    return mutual_info_score(None, None, contingency=hist_2d)\n",
    "\n",
    "mi_align = calculate_mutual_info(aligned_t2, aligned_t2)\n",
    "mi_misalign = calculate_mutual_info(aligned_t2, misaligned_t2_rigid)\n",
    "mi_misalign2 = calculate_mutual_info(aligned_t2, misaligned_t2_elastic)\n",
    "\n",
    "print(f\"Mutual Information: {mi_align} -> {mi_misalign}\")\n",
    "print(f\"Mutual Information: {mi_align} -> {mi_misalign2}\")\n",
    "\n",
    "print((mi_align - mi_misalign) / mi_align)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through misalignment process for each slice (dataA -> dataB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `PersistentDataset` processes original data sources through the non-random transforms on first use, and stores these intermediate tensor values to an on-disk persistence representation.\n",
    "- The intermediate processed tensors are loaded from disk on each use for processing by the random-transforms for each analysis request.\n",
    "- The `PersistentDataset` has a similar memory footprint to the simple Dataset, with performance characteristics close to the CacheDataset at the expense of disk storage.\n",
    "- Additionally, the cost of first time processing of data is distributed across each first use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data_x shape: \", f['data_x'].shape)\n",
    "print(\"data_y shape: \", f['data_y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_array(array, block_size):\n",
    "    \"\"\"\n",
    "    Slice a 3D NumPy array into smaller blocks along the third dimension.\n",
    "\n",
    "    Args:\n",
    "        array (numpy.ndarray): Input array to be sliced. It should have 3 dimensions.\n",
    "        block_size (int): Size of each block along the third dimension.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Sliced array with shape (array.shape[0], array.shape[1], block_size, num_slices),\n",
    "            where num_slices is array.shape[2] divided by block_size.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the input array does not have 3 dimensions or the block size does not evenly divide\n",
    "            the shape of the input array along the third dimension.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(array.shape) == 3, \"Input array should have 3 dimensions.\"\n",
    "    assert array.shape[2] % block_size == 0, \"Block size should evenly divide the array shape.\"\n",
    "\n",
    "    num_slices = array.shape[2] // block_size\n",
    "    sliced_array = np.zeros((array.shape[0], array.shape[1], block_size, num_slices))\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * block_size\n",
    "        end_idx = (i + 1) * block_size\n",
    "        sliced_array[:, :, :, i] = array[:, :, start_idx:end_idx]\n",
    "\n",
    "    return sliced_array\n",
    "\n",
    "def save_slices_to_nii(sliced_array, output_prefix):\n",
    "    \"\"\"\n",
    "    Save the individual slices of a 4D NumPy array as NIfTI files.\n",
    "\n",
    "    Args:\n",
    "        sliced_array (numpy.ndarray): Input array containing the slices to be saved. It should have 4 dimensions.\n",
    "        output_prefix (str): Prefix to be used for the output file names.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the input array does not have 4 dimensions.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(sliced_array.shape) == 4, \"Input array should have 4 dimensions.\"\n",
    "\n",
    "    for i in range(sliced_array.shape[3]):\n",
    "        data = sliced_array[:, :, :, i]\n",
    "        nifti_img = nib.Nifti1Image(data, affine=np.eye(4))\n",
    "        output_filename = f\"{output_prefix}_{i+1}.nii.gz\"\n",
    "        nib.save(nifti_img, output_filename)\n",
    "\n",
    "# Load File\n",
    "f = h5py.File('datasets/IXI/train/data.mat','r')\n",
    "\n",
    "# Example usage\n",
    "array = f['data_x'][...,0]\n",
    "block_size = 91\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/train/t1\"\n",
    "save_slices_to_nii(sliced_array, output_prefix)\n",
    "\n",
    "array = f['data_y'][...,0]\n",
    "block_size = 91\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/train/t2\"\n",
    "save_slices_to_nii(sliced_array, output_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_affine_transform = RandAffine(\n",
    "    mode=\"bilinear\",\n",
    "    prob=1.0,\n",
    "    spatial_size=None,\n",
    "    rotate_range=(0.2, 0.2, 0.2),  # Rotation range in radians\n",
    "    shear_range=(0.1, 0.1, 0.1),   # Shear range\n",
    "    translate_range=(5, 5, 5),  # Translation range in pixels\n",
    "    padding_mode=\"border\",\n",
    ")\n",
    "\n",
    "rand_3d_elastic_transform = Rand3DElastic(\n",
    "    mode=\"nearest\",\n",
    "    prob=1.0,\n",
    "    sigma_range=(5, 8), # Sigma range for smoothing random displacement\n",
    "    magnitude_range=(0.1, 0.1, 0.1), # Deformation magnitude\n",
    "    rotate_range=(0.1, 0.1, 0.1),\n",
    "    shear_range=(0.05, 0.05, 0.05),\n",
    "    translate_range=(3, 3, 3),\n",
    "    padding_mode=\"border\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import first\n",
    "\n",
    "root_dir = 'datasets/IXI/train'\n",
    "t1s = sorted(glob.glob(os.path.join(root_dir, \"t1*.nii.gz\")))\n",
    "t2s = sorted(glob.glob(os.path.join(root_dir, \"t2*.nii.gz\")))\n",
    "\n",
    "imtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        rand_3d_elastic_transform\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = ArrayDataset(t1s, imtrans, t2s, segtrans)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im1, im2 = first(loader)\n",
    "print(im1.shape, im2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow3d(im2[0,0,:,:,20:26], frame_dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from monai.config import DtypeLike\n",
    "from monai.data import ImageDataset, Dataset\n",
    "from monai.data.image_reader import ImageReader\n",
    "from monai.utils import MAX_SEED, get_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = ImageDataset(\n",
    "    image_files=img_list,\n",
    "    seg_files=seg_list,\n",
    "    transform=img_xform,\n",
    "    seg_transform=seg_xform,\n",
    "    image_only=False,\n",
    "    transform_with_metadata=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n",
    "\n",
    "def transformations():\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            # LoadImaged with image_only=True is to return the MetaTensors\n",
    "            # the additional metadata dictionary is not returned.\n",
    "            LoadImaged(keys=[\"image\", \"label\"], image_only=True),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                pixdim=(1.5, 1.5, 2.0),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            ),\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-57,\n",
    "                a_max=164,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            ),\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "            # randomly crop out patch samples from big\n",
    "            # image based on pos / neg ratio\n",
    "            # the image centers of negative samples\n",
    "            # must be in valid image area\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                label_key=\"label\",\n",
    "                spatial_size=(96, 96, 96),\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=4,\n",
    "                image_key=\"image\",\n",
    "                image_threshold=0,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # NOTE: No random cropping in the validation data,\n",
    "    # we will evaluate the entire image using a sliding window.\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            # LoadImaged with image_only=True is to return the MetaTensors\n",
    "            # the additional metadata dictionary is not returned.\n",
    "            LoadImaged(keys=[\"image\", \"label\"], image_only=True),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                pixdim=(1.5, 1.5, 2.0),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            ),\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-57,\n",
    "                a_max=164,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            ),\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ]\n",
    "    )\n",
    "    return train_transforms, val_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Compose, ToTensor, Resize\n",
    "\n",
    "# Define the MONAI RandAffine transform\n",
    "rand_affine_transform = RandAffine(\n",
    "    mode=\"bilinear\",\n",
    "    prob=1.0,\n",
    "    spatial_size=None,\n",
    "    rotate_range=(0.2, 0.2),  # Rotation range in radians\n",
    "    shear_range=(0.1, 0.1),   # Shear range\n",
    "    translate_range=(5, 5),  # Translation range in pixels\n",
    "    padding_mode=\"border\",\n",
    ")\n",
    "\n",
    "# Define the MONAI Rand2DElastic transform\n",
    "rand_2d_elastic_transform = Rand2DElastic(\n",
    "    mode=\"bilinear\",\n",
    "    prob=1.0,\n",
    "    spacing=(30, 30), # Distance between control points\n",
    "    magnitude_range=(0.1, 0.1), # Deformation magnitude\n",
    "    rotate_range=(0.1, 0.1),\n",
    "    shear_range=(0.1, 0.1),\n",
    "    translate_range=(5, 5),\n",
    "    padding_mode=\"border\",\n",
    ")\n",
    "\n",
    "transform = Compose([ToTensor()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with persistent storage\n",
    "dataset = PersistentDataset(\n",
    "    data=[{\"image\": torch.randn(256, 256), \"label\": torch.randint(0, 2, (256, 256))} for _ in range(1000)],\n",
    "    cache_dir=\"./cache\",  # Directory to store the dataset cache\n",
    "    refresh=False  # Whether to refresh the cache if it already exists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_new_1 : t1, t2_align, t2_misalign, mutual_info\n",
    "\n",
    "# data_new_2 : t1, t2_align, t2_misalign, mutual_info\n",
    "\n",
    "# data_new_3 : t1, t2_align, t2_misalign, mutual_info\n",
    "\n",
    "# data_new_4 : t1, t2_align, t2_misalign, mutual_info\n",
    "\n",
    "# data_new_5 : t1, t2_align, t2_misalign, mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import matshow3d, blend_images\n",
    "\n",
    "matshow3d(np.concatenate((f['data_x'][:,:,20:24,0],f['data_y'][:,:,20:24,0]),1), frame_dim=-1, show=True, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import Generator, Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Network\n",
    "from monai.networks.nets import AttentionUnet\n",
    "\n",
    "ngf = 24\n",
    "net = AttentionUnet(spatial_dims=2, in_channels=1, out_channels=1, channels=(ngf, ngf*2, ngf*4, ngf*8), strides=[1, 1, 1, 1])\n",
    "\n",
    "inp = torch.randn(1, 1, 256, 256)\n",
    "out = net(inp)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import AttentionUnet, Discriminator\n",
    "\n",
    "class CycleGAN(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, ngf=32, ndf=64):\n",
    "        super(CycleGAN, self).__init__()\n",
    "\n",
    "        # Generators\n",
    "        self.gen_AtoB = AttentionUnet(spatial_dims=2, in_channels, out_channels, channels=(ngf, ngf*2, ngf*4, ngf*8), strides=[1])\n",
    "        self.gen_BtoA = AttentionUnet(spatial_dims=2, in_channels, out_channels, channels=(ngf, ngf*2, ngf*4, ngf*8), strides=[1])\n",
    "\n",
    "        # Discriminators\n",
    "        self.dis_A = Discriminator(in_channels, channels=(ndf, ndf*2, ndf*4, ndf*8))\n",
    "        self.dis_B = Discriminator(in_channels, channels=(ndf, ndf*2, ndf*4, ndf*8))\n",
    "\n",
    "    def forward(self, real_A, real_B):\n",
    "        fake_B = self.gen_AtoB(real_A)\n",
    "        cycle_A = self.gen_BtoA(fake_B)\n",
    "\n",
    "        fake_A = self.gen_BtoA(real_B)\n",
    "        cycle_B = self.gen_AtoB(fake_A)\n",
    "\n",
    "        # Discriminator outputs\n",
    "        real_A_dis_out = self.dis_A(real_A)\n",
    "        fake_A_dis_out = self.dis_A(fake_A)\n",
    "\n",
    "        real_B_dis_out = self.dis_B(real_B)\n",
    "        fake_B_dis_out = self.dis_B(fake_B)\n",
    "\n",
    "        return fake_A, fake_B, cycle_A, cycle_B, real_A_dis_out, real_B_dis_out, fake_A_dis_out, fake_B_dis_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CycleGAN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misalign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
