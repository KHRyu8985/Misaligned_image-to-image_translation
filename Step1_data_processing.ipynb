{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch, monai\n",
    "import torchio as tio\n",
    "from typing import Sequence\n",
    "from monai.data import ArrayDataset, DataLoader, PersistentDataset\n",
    "from monai.transforms import Compose, RandAffine, Rand2DElastic, Rand3DElastic\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import nibabel as nib\n",
    "from utils import *\n",
    "\n",
    "import glob, os\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Rand3DElastic,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    RandFlip,\n",
    "    RandRotate90\n",
    ")\n",
    "\n",
    "from monai.utils import first\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.utils.set_determinism(10) # Fixes the seed (for reproducibility)\n",
    "monai.config.deviceconfig.print_config() # Prints PyTorch GPU information and MONAI dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('datasets/IXI/train/data.mat','r')\n",
    "\n",
    "print(\"data_x shape: \", f['data_x'].shape)\n",
    "print(\"data_y shape: \", f['data_y'].shape)\n",
    "\n",
    "t1 = f['data_x'][:,:,20,0] # One slice of t1 (256,256)\n",
    "t2 = f['data_y'][:,:,20,0] # One slice of t2 (256, 256)\n",
    "\n",
    "blended_align = blend_and_transpose(t1, t2) # Blend two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([blended_align, t1,t2], ['Blended', 'T1', 'T2']) # Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = matshow3d(f['data_x'][:,:,30:36,0], frame_dim=-1, show=True, cmap='gray', figsize=(7,7)) # Plot 3D image (multi-slice) TODO: matshow3d 에 관련된 옵션들 확인해보기 -> 노션에다가 정리\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Training dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Change `data.mat` to `t1_xx.nii` and `t2_xx.nii` files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subject별로 있어서, misalign simulation 하기 편함 (3D translation, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load File\n",
    "f = h5py.File('datasets/IXI/train/data.mat','r')\n",
    "\n",
    "# Training\n",
    "# T1\n",
    "array = f['data_x'][...,0] # first slice in t1\n",
    "block_size = 91 # 91 slices in one subject\n",
    "sliced_array = slice_array(array, block_size) # TODO: slice_array 함수 확인해보기\n",
    "output_prefix = \"datasets/IXI/train/t1\"\n",
    "save_slices_to_nii(sliced_array, output_prefix) # See the definition in utils.py file\n",
    "\n",
    "# T2\n",
    "array = f['data_y'][...,0]\n",
    "block_size = 91\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/train/t2\"\n",
    "save_slices_to_nii(sliced_array, output_prefix)\n",
    "\n",
    "# Validation\n",
    "f = h5py.File('datasets/IXI/val/data.mat','r')\n",
    "\n",
    "# T1\n",
    "array = f['data_x'][...,0] # first slice in t1\n",
    "block_size = 91 # 91 slices in one subject\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/val/t1\"\n",
    "save_slices_to_nii(sliced_array, output_prefix) \n",
    "\n",
    "# T2\n",
    "array = f['data_y'][...,0]\n",
    "block_size = 91\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/val/t2\"\n",
    "save_slices_to_nii(sliced_array, output_prefix)\n",
    "\n",
    "# Testing\n",
    "f = h5py.File('datasets/IXI/test/data.mat','r')\n",
    "\n",
    "# T1\n",
    "array = f['data_x'][...,0] # first slice in t1\n",
    "block_size = 91 # 91 slices in one subject\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/test/t1\"\n",
    "save_slices_to_nii(sliced_array, output_prefix) \n",
    "\n",
    "# T2\n",
    "array = f['data_y'][...,0]\n",
    "block_size = 91\n",
    "sliced_array = slice_array(array, block_size)\n",
    "output_prefix = \"datasets/IXI/test/t2\"\n",
    "save_slices_to_nii(sliced_array, output_prefix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply misalignment for each subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3d image: 9it [00:02,  4.56it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_3d_elastic_transform = Rand3DElastic(\n",
    "    mode=\"nearest\",\n",
    "    prob=1.0,\n",
    "    sigma_range=(3, 5), # Sigma range for smoothing random displacement\n",
    "    magnitude_range=(0.1, 0.1, 0.1), # Deformation magnitude\n",
    "    rotate_range=(0.1, 0.1, 0.1),\n",
    "    shear_range=(0.025, 0.025, 0.025),\n",
    "    translate_range=(3, 3, 3),\n",
    "    padding_mode=\"border\"\n",
    ") # Changed a bit\n",
    "# Define the misalignment process\n",
    "# TODO: modify the parameters above to simulate various misalignment (perfect alignment -> ... --> perfect misalignment) 5개 정도 Stage 만들기 및 실험\n",
    "# TODO: Parameters are dependent on the result (in Step2_PGAN.ipynb)\n",
    "\n",
    "root_dir = 'datasets/IXI/train'\n",
    "t1s = sorted(glob.glob(os.path.join(root_dir, \"t1*.nii.gz\")))\n",
    "t2s = sorted(glob.glob(os.path.join(root_dir, \"t2*.nii.gz\")))\n",
    "\n",
    "imtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        #rand_3d_elastic_transform # TODO: We first test Step2_PGAN.ipynb without misalignment\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = ArrayDataset(t1s, imtrans, t2s, segtrans) # MONAI ArrayDataset (MONAI Framework)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im1, im2 = first(loader)\n",
    "print(im1.shape, im2.shape)\n",
    "\n",
    "# Save training dataset to numpy array file (Slice by Slice)\n",
    "for idx, (im1, im2) in tqdm(enumerate(loader), desc='3d image'):\n",
    "    nslice = im1.shape[-1]\n",
    "    for sl in range(nslice):\n",
    "        np.save(f'datasets/IXI/train/t1_{idx}_{sl}.npy', im1[...,sl].squeeze())\n",
    "        np.save(f'datasets/IXI/train/t2_{idx}_{sl}.npy', im2[...,sl].squeeze())\n",
    "        \n",
    "        # TODO: compute misalignment metric (mutual information) for 3D image (T1 and misaligned T1, misaligned T1 and T2) @ Danny Kim\n",
    "        # TODO: Then save the metric to a file (e.g. np.save(f'datasets/IXI/train/metric_{idx}.npy', metric)) @ Danny Kim\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the actual dataset (Patched 96x96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'datasets/IXI/train'\n",
    "\n",
    "t1s = sorted(glob.glob(os.path.join(root_dir, \"t1*.npy\")))\n",
    "t2s = sorted(glob.glob(os.path.join(root_dir, \"t2*.npy\")))\n",
    "\n",
    "t1_trans = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True, ensure_channel_first=True),\n",
    "            ScaleIntensity(),\n",
    "            RandSpatialCrop((64, 64), random_size=False),\n",
    "            RandFlip(prob=0.5, spatial_axis=0),\n",
    "            RandFlip(prob=0.5, spatial_axis=1),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "t2_trans = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True, ensure_channel_first=True),\n",
    "            ScaleIntensity(),\n",
    "            RandSpatialCrop((64, 64), random_size=False),\n",
    "            RandFlip(prob=0.5, spatial_axis=0),\n",
    "            RandFlip(prob=0.5, spatial_axis=1),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# define array dataset, data loader\n",
    "check_ds = ArrayDataset(t1s, t1_trans, t2s, t2_trans)\n",
    "check_loader = DataLoader(check_ds, batch_size=30, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "t1, t2 = monai.utils.misc.first(check_loader)\n",
    "print(t1.shape, t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = matshow3d(t1, show=True, cmap='gray',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = matshow3d(t2, show=True, cmap='gray',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_blended_images(t1,t2) # plot blended images (Use this function to plot the blended images of size: torch.Size([30, 1, 64, 64]) torch.Size([30, 1, 64, 64]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process validation and test dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Validation and Test dataset has no misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = 'datasets/IXI/val'\n",
    "t1s = sorted(glob.glob(os.path.join(root_dir, \"t1*.nii.gz\")))\n",
    "t2s = sorted(glob.glob(os.path.join(root_dir, \"t2*.nii.gz\")))\n",
    "\n",
    "imtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = ArrayDataset(t1s, imtrans, t2s, segtrans)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im1, im2 = first(loader)\n",
    "print(im1.shape, im2.shape)\n",
    "\n",
    "# Save training dataset to numpy array file (Slice by Slice)\n",
    "for idx, (im1, im2) in tqdm(enumerate(loader), desc='3d image'):\n",
    "    nslice = im1.shape[-1]\n",
    "    for sl in range(nslice):\n",
    "        np.save(f'datasets/IXI/val/t1_{idx}_{sl}.npy', im1[...,sl].squeeze())\n",
    "        np.save(f'datasets/IXI/val/t2_{idx}_{sl}.npy', im2[...,sl].squeeze())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = 'datasets/IXI/test'\n",
    "t1s = sorted(glob.glob(os.path.join(root_dir, \"t1*.nii.gz\")))\n",
    "t2s = sorted(glob.glob(os.path.join(root_dir, \"t2*.nii.gz\")))\n",
    "\n",
    "imtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = ArrayDataset(t1s, imtrans, t2s, segtrans)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im1, im2 = first(loader)\n",
    "print(im1.shape, im2.shape)\n",
    "\n",
    "# Save training dataset to numpy array file (Slice by Slice)\n",
    "for idx, (im1, im2) in tqdm(enumerate(loader), desc='3d image'):\n",
    "    nslice = im1.shape[-1]\n",
    "    for sl in range(nslice):\n",
    "        np.save(f'datasets/IXI/test/t1_{idx}_{sl}.npy', im1[...,sl].squeeze())\n",
    "        np.save(f'datasets/IXI/test/t2_{idx}_{sl}.npy', im2[...,sl].squeeze())\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: make the whole code into a single code (that saves auxilary images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Step1_data_processing_daniel.ipynb \n",
    "# TODO: -> prepare.py 로 정리 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misalign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
